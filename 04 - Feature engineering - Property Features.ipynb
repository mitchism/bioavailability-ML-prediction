{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06f8b07",
   "metadata": {},
   "source": [
    "# First improvement attempts:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72a3c3c",
   "metadata": {},
   "source": [
    "### <font color='blue'> Investigate improvements to feature selection / engineering </font>\n",
    "\n",
    "* <font color='gray'> _statistical & data engineering considerations:_ </font>\n",
    "    <br><font color='gray'> 1. comparison between scaled and unscaled features</font>\n",
    "    <br><font color='gray'> 2. elimination of highly cross-correlated variables</font>\n",
    "    <br><font color='gray'> 3. variable exclusion through ANOVA significance tests</font> <br>\n",
    "* <font color='gray'> _scientific (e.g. chemistry) considerations:_ </font>\n",
    "    <br><font color='gray'> 4. use of the VSA metrics: presence vs. absence </font>\n",
    "    <br><font color='gray'> 5. type of the VSA metric: surface area vs. percent of surface area</font>\n",
    "    <br><font color='gray'> 6. reducing features to retain only widely-accepted factors affecting drug bioavailability</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213a96a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('BApredsV1').getOrCreate()\n",
    "\n",
    "# load the data\n",
    "data = spark.read.csv(\"bioavailability_data_final.csv\",inferSchema=True,sep=',',header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9531b41",
   "metadata": {},
   "source": [
    "* first, let's start by splitting the features into each VSA type:  **quantity VSA** _vs._ **percentage of VSA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4238658",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# FEATURE SET 1a/1b: compare two variants of VSA calculation\n",
    "'''\n",
    "# set1a features property_VSA ranges each in absolute quantity VSA\n",
    "feature_set1a = ['MolWt','ExactMolWt','qed','MolLogP','MolMR','VSA_total','LabuteASA','TPSA',\n",
    "                 'MaxPartialCharge','MinPartialCharge','MaxAbsPartialCharge','MinAbsPartialCharge',\n",
    "                 'NumHAcceptors','NumHDonors','HeavyAtomCount','NumHeteroatoms','NumRotatableBonds',\n",
    "                 'NHOHCount','NOCount','FractionCSP3','RingCount','NumAliphaticRings','NumAromaticRings',\n",
    "                 'NumAliphaticHeterocycles','NumAromaticHeterocycles','NumSaturatedHeterocycles',\n",
    "                 'NumSaturatedRings','BalabanJ','BertzCT','HallKierAlpha',\n",
    "                 'PEOE_VSA1','PEOE_VSA2','PEOE_VSA3','PEOE_VSA4','PEOE_VSA5','PEOE_VSA6','PEOE_VSA7',\n",
    "                 'PEOE_VSA8','PEOE_VSA9','PEOE_VSA10','PEOE_VSA11','PEOE_VSA12','PEOE_VSA13','PEOE_VSA14',\n",
    "                 'SMR_VSA1','SMR_VSA2','SMR_VSA3','SMR_VSA4','SMR_VSA5','SMR_VSA6','SMR_VSA7','SMR_VSA8',\n",
    "                 'SMR_VSA9','SMR_VSA10','SlogP_VSA1','SlogP_VSA2','SlogP_VSA3','SlogP_VSA4','SlogP_VSA5',\n",
    "                 'SlogP_VSA6','SlogP_VSA7','SlogP_VSA8','SlogP_VSA9','SlogP_VSA10','SlogP_VSA11','SlogP_VSA12']\n",
    "\n",
    "# set1a features property_VSA ranges each in relative quantity (percent) of total VSA\n",
    "feature_set1b = ['MolWt','ExactMolWt','qed','MolLogP','MolMR','VSA_total','LabuteASA','TPSA',\n",
    "                   'MaxPartialCharge','MinPartialCharge','MaxAbsPartialCharge','MinAbsPartialCharge',\n",
    "                   'NumHAcceptors','NumHDonors','HeavyAtomCount','NumHeteroatoms','NumRotatableBonds',\n",
    "                   'NHOHCount','NOCount','FractionCSP3','RingCount','NumAliphaticRings','NumAromaticRings',\n",
    "                   'NumAliphaticHeterocycles','NumAromaticHeterocycles','NumSaturatedHeterocycles',\n",
    "                   'NumSaturatedRings','BalabanJ','BertzCT','HallKierAlpha',\n",
    "                   'fracVSA_PEOE01','fracVSA_PEOE02','fracVSA_PEOE03','fracVSA_PEOE04','fracVSA_PEOE05',\n",
    "                   'fracVSA_PEOE06','fracVSA_PEOE07','fracVSA_PEOE08','fracVSA_PEOE09','fracVSA_PEOE10',\n",
    "                   'fracVSA_PEOE11','fracVSA_PEOE12','fracVSA_PEOE13','fracVSA_PEOE14',\n",
    "                   'fracVSA_SMR01','fracVSA_SMR02','fracVSA_SMR03','fracVSA_SMR04','fracVSA_SMR05',\n",
    "                   'fracVSA_SMR06','fracVSA_SMR07','fracVSA_SMR08','fracVSA_SMR09','fracVSA_SMR10',\n",
    "                   'fracVSA_SlogP01','fracVSA_SlogP02','fracVSA_SlogP03','fracVSA_SlogP04',\n",
    "                   'fracVSA_SlogP05','fracVSA_SlogP06','fracVSA_SlogP07','fracVSA_SlogP08',\n",
    "                   'fracVSA_SlogP09','fracVSA_SlogP10','fracVSA_SlogP11','fracVSA_SlogP12']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4298e6",
   "metadata": {},
   "source": [
    "* next, let's eliminate highly cross-correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16beee",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# FEATURE SET 2a/2b: copy feature set 1a/1b and remove highly [e.g. 95%] cross-correlated vars\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set 2a is derived from Set 1a\n",
    "feature_set2a = []\n",
    "df = data.select(feature_set1a).toPandas()\n",
    "corr_matrix = df.corr().abs() # builds correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool)) # top-right triangle of matrix\n",
    "cols_to_drop = [column for column in upper.columns if any(upper[column] > 0.95)] # isolate features w/ corr > 0.95\n",
    "for item in feature_set1a:\n",
    "    if item in cols_to_drop: \n",
    "        pass\n",
    "    else:\n",
    "        feature_set2a.append(item) \n",
    "        \n",
    "# Set 2b is derived from Set 1b\n",
    "feature_set2b = []\n",
    "df = data.select(feature_set1b).toPandas()\n",
    "corr_matrix = df.corr().abs() # builds correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool)) # top-right triangle of matrix\n",
    "cols_to_drop = [column for column in upper.columns if any(upper[column] > 0.95)] # isolate features w/ corr > 0.95\n",
    "for item in feature_set1b:\n",
    "    if item in cols_to_drop: \n",
    "        pass\n",
    "    else:\n",
    "        feature_set2b.append(item) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8090477b",
   "metadata": {},
   "source": [
    "* check the effect of entirely skipping any VSA calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b57f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE SELECTION (3): feature set 2, minus VSA/fracVSA related calculations\n",
    "feature_set3 = ['MolWt', 'qed', 'MolLogP', 'TPSA', \n",
    "                'MaxPartialCharge', 'MinPartialCharge', \n",
    "                'NumHAcceptors', 'NumHDonors', 'NumHeteroatoms', \n",
    "                 'NumRotatableBonds', 'FractionCSP3', \n",
    "                'RingCount', 'NumAliphaticRings', 'NumAromaticRings',\n",
    "                 'NumAliphaticHeterocycles', 'NumAromaticHeterocycles', \n",
    "                 'NumSaturatedHeterocycles', 'NumSaturatedRings', \n",
    "                'BalabanJ', 'BertzCT', 'HallKierAlpha']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e86a2d",
   "metadata": {},
   "source": [
    "* check the effect if we keep **only** metrics widely recognized to influence bioavailability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "# FEATURE SETS 4a/4b: Keep only the criteria relevant for Lipinski, Ghose, Veber, REOS (etc.) filters/rules.  \n",
    "'''\n",
    "# feature set 4a uses NHOH / NO counts instead of H donor/acceptor \n",
    "feature_set4a = ['MolWt', \n",
    "                 'MolLogP',\n",
    "                 'MolMR',\n",
    "                 'TPSA',\n",
    "                 'NHOHCount','NOCount',\n",
    "                 'FractionCSP3',\n",
    "                 'NumRotatableBonds',\n",
    "                 'HeavyAtomCount']\n",
    "\n",
    "# feature set 4b uses H donor/acceptor counts instead of NHOH/NO counts              \n",
    "feature_set4b = ['MolWt', \n",
    "                 'MolLogP',\n",
    "                 'MolMR',\n",
    "                 'TPSA',\n",
    "                 'NumHAcceptors','NumHDonors',\n",
    "                 'FractionCSP3',\n",
    "                 'NumRotatableBonds',\n",
    "                 'HeavyAtomCount']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7f8ed8",
   "metadata": {},
   "source": [
    "* ANOVA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b24f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# ANOVA between Low / Medium / High BA ... versus features\n",
    "'''\n",
    "# calculate statistic\n",
    "import scipy.stats\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# select data subset w/ drug name, BA_pct, and feature set 1b \n",
    "cols_temp = ['Name','BA_pct']\n",
    "cols_temp.extend(list(feature_set1b))\n",
    "df_temp1 = data.select(cols_temp)\n",
    "\n",
    "# ANOVA will need a categorical label column, so here we group BA_pct into 3 buckets\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "bucketizer = Bucketizer(splits=[0, 33.3, 66.7, float('Inf')],inputCol=\"BA_pct\", outputCol=\"label_bin3\")\n",
    "df_out2 = bucketizer.setHandleInvalid(\"keep\").transform(df_temp1)\n",
    "\n",
    "# select all columns and send to Pandas\n",
    "cols_temp = ['Name','BA_pct','label_bin3']\n",
    "cols_temp.extend(list(feature_set1b))\n",
    "df_out2 = df_out2.select(cols_temp).toPandas()\n",
    "\n",
    "# assign names to the three groups for ANOVA \n",
    "low = df_out2[df_out2['label_bin3']==0]\n",
    "mid = df_out2[df_out2['label_bin3']==1]\n",
    "hi = df_out2[df_out2['label_bin3']==2]\n",
    "\n",
    "#calculate P-Value in each ANOVA group\n",
    "varlist = list(feature_set1b)\n",
    "vars_to_keep = []\n",
    "vars_failed = []\n",
    "for var_x in varlist:\n",
    "    f_stat,p_val = f_oneway(low[var_x],mid[var_x],hi[var_x])\n",
    "    def check(p_val):\n",
    "        if p_val < 0.05:\n",
    "            return 'ok'\n",
    "        else:\n",
    "            return 'FAIL'\n",
    "    independence = check(p_val)\n",
    "    if independence == 'ok':\n",
    "        vars_to_keep.append(var_x)\n",
    "    else:\n",
    "        vars_failed.append(var_x)\n",
    "\n",
    "# remove variables not passing ANOVA test from feature Sets 1b and 2b\n",
    "F2bANOVA = list(feature_set2b)\n",
    "F1bANOVA = list(feature_set1b)\n",
    "for var_x in vars_failed: \n",
    "    F1bANOVA.remove(var_x)\n",
    "    if var_x in F2bANOVA:\n",
    "        F2bANOVA.remove(var_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1781f018",
   "metadata": {},
   "source": [
    "* save all feature-set variants as a features catalog, for quick later reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc70b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresCatalog = {}\n",
    "featuresIndexDict = {}\n",
    "\n",
    "featnum = ['F1a','F1b','F2a','F2b','F3','F4a','F4b','F1bANOVA','F2bANOVA']\n",
    "\n",
    "featDescrip = ['F1a: All calculations, with Property-VSA ranges given as quantity SA per Property.',\n",
    "               'F1b: All calculations, with Property-VSA ranges given as percent SA per Property.',\n",
    "               'F2a: Same as F1a, but excluding all features having cross correlations of > 0.95.',\n",
    "               'F2b: Same as F1b, but excluding all features having cross correlations of > 0.95.',\n",
    "               'F3: Same as F2a/F2b, but excluding Property-VSA ranges.',\n",
    "               'F4a: Metrics related to common filters (Lipinski, Ghose, Veber, REOS); uses NHOH/NO counts instead of H-donor/H-acceptor counts.',\n",
    "               'F4a: Metrics related to common filters (Lipinski, Ghose, Veber, REOS); uses H-donor/H-acceptor counts instead of NHOH/NO counts.',\n",
    "               'F1bANOVA: F1b vars passing ANOVA (0.05 Sig.) across 3 bioavailability groups (low/mid/hi)',\n",
    "               'F2bANOVA: F2b vars passing ANOVA (0.05 Sig.) across 3 bioavailability groups (low/mid/hi)']\n",
    "\n",
    "featVariants = [feature_set1a,feature_set1b,\n",
    "                feature_set2a,feature_set2b,\n",
    "                feature_set3,\n",
    "                feature_set4a,feature_set4b,\n",
    "                F1bANOVA, F2bANOVA]\n",
    "\n",
    "i = 0\n",
    "for featList in featVariants:\n",
    "    featName = featnum[i]\n",
    "    \n",
    "    featuresIndexDict[featName] = featList\n",
    "    \n",
    "    featuresCatalog[i] = {}\n",
    "    featuresCatalog[i]['name'] = featName\n",
    "    featuresCatalog[i]['description'] = featDescrip[i]\n",
    "    featuresCatalog[i]['featureCount'] = len(featList)\n",
    "    featuresCatalog[i]['features'] = featList\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "featuresDF = pd.DataFrame.from_dict(featuresCatalog,orient='index',dtype=object)\n",
    "featuresDF = featuresDF.infer_objects()\n",
    "featuresDF.dtypes\n",
    "\n",
    "featuresDF.to_pickle('featuresCatalogDF_2022-08-17_new.pickle')\n",
    "featuresDF.to_parquet('featuresCatalogDF_2022-08-17_new.parquet')\n",
    "\n",
    "featuresDF.head(7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
