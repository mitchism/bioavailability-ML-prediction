{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ddb689a",
   "metadata": {},
   "source": [
    "# ML Trial 01 \n",
    "### _Test predictive performance using all Property features_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3100c4f9",
   "metadata": {},
   "source": [
    "* specify spark environment for this pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "606cd755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSM VM config prep\n",
    "import findspark\n",
    "findspark.init('/home/mitch/spark-3.3.0-bin-hadoop2')\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b840a44",
   "metadata": {},
   "source": [
    "* create a spark session & load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "013698ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('BApredsV1').getOrCreate()\n",
    "\n",
    "# --- suppress future spark warnings/error/etc output ---\n",
    "spark.sparkContext.setLogLevel(\"OFF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb5dbd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_pickle(\"data/bioavailability_data_wFeatures.pkl\")\n",
    "data = data.rename(columns={'Name':'name','_c0':'index'})\n",
    "data = data.drop(columns='drug_name')\n",
    "data = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93c8c1a",
   "metadata": {},
   "source": [
    "#### first regression and classification test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d6d3f9",
   "metadata": {},
   "source": [
    "* prepare feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1b0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_feature = ['MolWt','ExactMolWt','qed','MolLogP','MolMR','VSA_total','LabuteASA','TPSA',\n",
    "                   'MaxPartialCharge','MinPartialCharge','MaxAbsPartialCharge','MinAbsPartialCharge',\n",
    "                   'NumHAcceptors','NumHDonors','HeavyAtomCount','NumHeteroatoms','NumRotatableBonds',\n",
    "                   'NHOHCount','NOCount','FractionCSP3','RingCount','NumAliphaticRings','NumAromaticRings',\n",
    "                   'NumAliphaticHeterocycles','NumAromaticHeterocycles','NumSaturatedHeterocycles',\n",
    "                   'NumSaturatedRings','BalabanJ','BertzCT','HallKierAlpha',\n",
    "                   'fracVSA_PEOE01','fracVSA_PEOE02','fracVSA_PEOE03','fracVSA_PEOE04','fracVSA_PEOE05',\n",
    "                   'fracVSA_PEOE06','fracVSA_PEOE07','fracVSA_PEOE08','fracVSA_PEOE09','fracVSA_PEOE10',\n",
    "                   'fracVSA_PEOE11','fracVSA_PEOE12','fracVSA_PEOE13','fracVSA_PEOE14',\n",
    "                   'fracVSA_SMR01','fracVSA_SMR02','fracVSA_SMR03','fracVSA_SMR04','fracVSA_SMR05',\n",
    "                   'fracVSA_SMR06','fracVSA_SMR07','fracVSA_SMR08','fracVSA_SMR09','fracVSA_SMR10',\n",
    "                   'fracVSA_SlogP01','fracVSA_SlogP02','fracVSA_SlogP03','fracVSA_SlogP04',\n",
    "                   'fracVSA_SlogP05','fracVSA_SlogP06','fracVSA_SlogP07','fracVSA_SlogP08',\n",
    "                   'fracVSA_SlogP09','fracVSA_SlogP10','fracVSA_SlogP11','fracVSA_SlogP12']\n",
    "\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer)\n",
    "\n",
    "vec_assembler = VectorAssembler(inputCols = cols_to_feature, outputCol='features')\n",
    "data_w_features = vec_assembler.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaac88c",
   "metadata": {},
   "source": [
    "* index/encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81a6e86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import (StringIndexer,OneHotEncoder)\n",
    "\n",
    "label_quant0 = 'BA_pct'\n",
    "\n",
    "label_cat1_index = StringIndexer(inputCol='label1',outputCol='label_cat1_index')\n",
    "\n",
    "label_cat2_index = StringIndexer(inputCol='label2',outputCol='label_cat2_index')\n",
    "\n",
    "label_cat3_index = StringIndexer(inputCol='label3a',outputCol='label_cat3_index')\n",
    "\n",
    "label_cat4_index = StringIndexer(inputCol='label3b',outputCol='label_cat4_index')\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "data_pipeline = Pipeline(stages=[label_cat1_index,\n",
    "                                 label_cat2_index,\n",
    "                                 label_cat3_index,\n",
    "                                 label_cat4_index])\n",
    "\n",
    "data_w_features = data_w_features.select(['Name','BA_pct','label_QD5','label1','label2','label3a','label3b','features'])\n",
    "data_prefinal = data_pipeline.fit(data_w_features).transform(data_w_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed03db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up data\n",
    "data_prefinal2 = data_prefinal.withColumnRenamed('BA_pct','label_q0')\n",
    "data_prefinal2 = data_prefinal2.withColumnRenamed('label_QD5','label_cat0')\n",
    "data_prefinal2 = data_prefinal2.withColumnRenamed('label_cat1_index','label_cat1')\n",
    "data_prefinal2 = data_prefinal2.withColumnRenamed('label_cat2_index','label_cat2')\n",
    "data_prefinal2 = data_prefinal2.withColumnRenamed('label_cat3_index','label_cat3')\n",
    "data_prefinal2 = data_prefinal2.withColumnRenamed('label_cat4_index','label_cat4')\n",
    "\n",
    "data_final = data_prefinal2.select(['Name',\n",
    "                                    'label_q0',\n",
    "                                    'label_cat0','label_cat1',\n",
    "                                    'label_cat2','label_cat3','label_cat4',\n",
    "                                    'features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085cba39",
   "metadata": {},
   "source": [
    "# Set up ML Flow experiment for ML Trial 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42180862",
   "metadata": {},
   "source": [
    "* test a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e1ac2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b34781e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: ML Trial 1\n",
      "Experiment_id: 1\n",
      "Artifact Location: file:///media/sf_Public/new%20BA%20folder/mlruns/trial1\n",
      "Tags: {'priority': 'P1', 'version': 'v1'}\n",
      "Lifecycle_stage: active\n",
      "Creation timestamp: 1664390446509\n"
     ]
    }
   ],
   "source": [
    "experiment_id = mlflow.create_experiment(\n",
    "    \"ML Trial 1\",\n",
    "    artifact_location=Path.cwd().joinpath(\"mlruns/trial1\").as_uri(),\n",
    "    tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
    ")\n",
    "experiment = mlflow.get_experiment(experiment_id)\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Tags: {}\".format(experiment.tags))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
    "print(\"Creation timestamp: {}\".format(experiment.creation_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6226363d",
   "metadata": {},
   "source": [
    "# Define trial runs with MLflow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff318671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml.regression import (LinearRegression,RandomForestRegressor,GBTRegressor,\n",
    "                                   DecisionTreeRegressor,GeneralizedLinearRegression)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    \n",
    "def evaluation(myresults):\n",
    "    \n",
    "    regEvaluator = RegressionEvaluator(labelCol='label_q0',predictionCol='prediction')\n",
    "    \n",
    "    evalMetrics = {regEvaluator:['rmse','mse','mae','r2','var']}\n",
    "    evaluator = regEvaluator\n",
    "    eval_results = {}\n",
    "    for each_metric in evalMetrics[evaluator]:\n",
    "        metric = each_metric\n",
    "        result = evaluator.evaluate(myresults, {evaluator.metricName: metric})\n",
    "\n",
    "        eval_results[each_metric] = result\n",
    "\n",
    "    #df_out = pd.DataFrame.from_dict(eval_results)\n",
    "    return eval_results\n",
    "\n",
    "def trial_run(train,test,trialName='trial1',modelType='linreg'):\n",
    "    features_choice = 'rdkit'\n",
    "    \n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.WARN)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    with mlflow.start_run(experiment_id=experiment_id,run_name=modelType):\n",
    "\n",
    "        if modelType=='linreg':\n",
    "            model = LinearRegression(featuresCol='features',labelCol='label_q0',predictionCol='prediction')\n",
    "        elif modelType=='glr':\n",
    "            model = GeneralizedLinearRegression(featuresCol='features',labelCol='label_q0',predictionCol='prediction')\n",
    "        elif modelType=='rfr':\n",
    "            model = RandomForestRegressor(featuresCol='features',labelCol='label_q0',predictionCol='prediction')\n",
    "        elif modelType=='dtr':\n",
    "            model = DecisionTreeRegressor(featuresCol='features',labelCol='label_q0',predictionCol='prediction')\n",
    "        elif modelType=='gbtr':\n",
    "            model = GBTRegressor(featuresCol='features',labelCol='label_q0',predictionCol='prediction')\n",
    "\n",
    "        mymodel = model.fit(train)\n",
    "        myresults = mymodel.transform(test)\n",
    "\n",
    "        #print(lmResults1A.rootMeanSquaredError, lmResults1A.r2)\n",
    "        eval_results = evaluation(myresults)\n",
    "        \n",
    "        print(f\"MODEL:\\t{modelType}\\nRMSE:\\t{eval_results['rmse']}\\nR2:\\t{eval_results['r2']}\")\n",
    "\n",
    "        ''' # LOG PARAMS & METRICS IN MLFLOW '''\n",
    "        mlflow.log_param(\"experiment\",mlflow.get_experiment(experiment_id).name)\n",
    "        mlflow.log_param(\"features\",features_choice)\n",
    "        mlflow.log_param(\"model type\",modelType)\n",
    "        mlflow.log_metric(\"rmse\", eval_results['rmse'])\n",
    "        mlflow.log_metric(\"mae\", eval_results['mae'])\n",
    "        mlflow.log_metric(\"r2\", eval_results['r2'])\n",
    "        mlflow.spark.log_model(mymodel,trialName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33871438",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = data_final.select(['label_q0','features'])\n",
    "        \n",
    "train,test = subset.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c3e935c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL:\tlinreg\n",
      "RMSE:\t29.93428244704524\n",
      "R2:\t0.18841203511998927\n"
     ]
    }
   ],
   "source": [
    "trial_run(train,test,'trial1','linreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caca3410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL:\tglr\n",
      "RMSE:\t29.93434126369391\n",
      "R2:\t0.1884088458047838\n"
     ]
    }
   ],
   "source": [
    "trial_run(train,test,'trial1','glr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce2af4a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL:\trfr\n",
      "RMSE:\t29.704073253033936\n",
      "R2:\t0.20084704741940584\n"
     ]
    }
   ],
   "source": [
    "trial_run(train,test,'trial1','rfr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9a52f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL:\tdtr\n",
      "RMSE:\t32.38434214493323\n",
      "R2:\t0.05012151182790403\n"
     ]
    }
   ],
   "source": [
    "trial_run(train,test,'trial1','dtr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dab7942f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL:\tgbtr\n",
      "RMSE:\t31.570289689979017\n",
      "R2:\t0.097275918803156\n"
     ]
    }
   ],
   "source": [
    "trial_run(train,test,'trial1','gbtr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d0be50",
   "metadata": {},
   "source": [
    "<font color='purple'> ***Observations:*** </font> <br>\n",
    "The r-squared value was best for the Random Forest regressor, followed by Linear Regression model.\n",
    "<br>\n",
    "<font color='orange'> ***Next step:*** </font> <br>\n",
    "This trial was conducted on all rdkit features, comparing different Regression models. <br> The next trial will compare different feature set variants of the rdkit features.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
