{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ddb689a",
   "metadata": {},
   "source": [
    "# First ML Trials _(without structural info)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b840a44",
   "metadata": {},
   "source": [
    "* create a spark session & load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013698ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('BApredsV1').getOrCreate()\n",
    "\n",
    "# load the data\n",
    "data = spark.read.csv(\"bioavailability_data_final.csv\",inferSchema=True,sep=',',header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4609d1",
   "metadata": {},
   "source": [
    "* <font color='gray'> Regarding data labels, recall that: </font>\n",
    "  * <font color='gray'> The data has 5 labels: </font>\n",
    "      *  <font color='gray'> **1 continuous label:** the BA percentage (_the original label_) </font> \n",
    "      *  <font color='gray'>**4 categorical labels:** the discretized groups of BA percentage </font> <br>\n",
    "  * <font color='gray'> The categorical label columns were created by dividing _BA percentage_ into groups. The _\"bucketing\"/discretization ranges_ for these divisions were determined based on the review of histogram distributions and label statistics (_e.g.,_ grouped label mean & stdev) </font>\n",
    "<br>\n",
    "* for comparison with the manually-labeled categorical columns, an additional categorical label column will be added using Spark's built-in **QuantileDiscretizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff82b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "import pandas as pd\n",
    "qd5 = QuantileDiscretizer(numBuckets=5,inputCol='BA_pct',outputCol='label_QD5')\n",
    "data = qd5.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bcb8a1",
   "metadata": {},
   "source": [
    "* <font color='blue'> _For a quick review of all data labels, let's display them in a grouped DF:_ </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087797e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' # FINAL LABELS:\n",
    "# ...1 continuous label column\n",
    "# ...5 categorical label columns\n",
    "# ---- label1 has 3 categories          -->                     low   /  mid   / high \n",
    "# ---- label2 has 4 categories          -->          very low / low       /      high / very high\n",
    "# ---- the rest have 5 categories       -->          very low / low / moderate / high / very high\n",
    "'''\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "data_wLabels.select(['BA_pct','label_QD5','label1','label2','label3a','label3b'])\\\n",
    "                .groupby('label_QD5','label3a','label3b','label2','label1')\\\n",
    "                    .agg(F.count('BA_pct'),F.min('BA_pct'),F.max('BA_pct'))\\\n",
    "                        .orderBy('max(BA_pct)')\\\n",
    "                            .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93c8c1a",
   "metadata": {},
   "source": [
    "#### first regression and classification test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d6d3f9",
   "metadata": {},
   "source": [
    "* prepare feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1b0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_feature = ['MolWt','ExactMolWt','qed','MolLogP','MolMR','VSA_total','LabuteASA','TPSA',\n",
    "                   'MaxPartialCharge','MinPartialCharge','MaxAbsPartialCharge','MinAbsPartialCharge',\n",
    "                   'NumHAcceptors','NumHDonors','HeavyAtomCount','NumHeteroatoms','NumRotatableBonds',\n",
    "                   'NHOHCount','NOCount','FractionCSP3','RingCount','NumAliphaticRings','NumAromaticRings',\n",
    "                   'NumAliphaticHeterocycles','NumAromaticHeterocycles','NumSaturatedHeterocycles',\n",
    "                   'NumSaturatedRings','BalabanJ','BertzCT','HallKierAlpha',\n",
    "                   'fracVSA_PEOE01','fracVSA_PEOE02','fracVSA_PEOE03','fracVSA_PEOE04','fracVSA_PEOE05',\n",
    "                   'fracVSA_PEOE06','fracVSA_PEOE07','fracVSA_PEOE08','fracVSA_PEOE09','fracVSA_PEOE10',\n",
    "                   'fracVSA_PEOE11','fracVSA_PEOE12','fracVSA_PEOE13','fracVSA_PEOE14',\n",
    "                   'fracVSA_SMR01','fracVSA_SMR02','fracVSA_SMR03','fracVSA_SMR04','fracVSA_SMR05',\n",
    "                   'fracVSA_SMR06','fracVSA_SMR07','fracVSA_SMR08','fracVSA_SMR09','fracVSA_SMR10',\n",
    "                   'fracVSA_SlogP01','fracVSA_SlogP02','fracVSA_SlogP03','fracVSA_SlogP04',\n",
    "                   'fracVSA_SlogP05','fracVSA_SlogP06','fracVSA_SlogP07','fracVSA_SlogP08',\n",
    "                   'fracVSA_SlogP09','fracVSA_SlogP10','fracVSA_SlogP11','fracVSA_SlogP12']\n",
    "\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer)\n",
    "\n",
    "vec_assembler = VectorAssembler(inputCols = cols_to_feature, outputCol='features')\n",
    "data_w_features = vec_assembler.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaac88c",
   "metadata": {},
   "source": [
    "* index/encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a6e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (StringIndexer,OneHotEncoder)\n",
    "\n",
    "label_quant0 = 'BA_pct'\n",
    "\n",
    "label_cat0_vector = OneHotEncoder(inputCol='label_QD5',outputCol='label_cat0_vector')\n",
    "\n",
    "label_cat1_index = StringIndexer(inputCol='label1',outputCol='label_cat1_index')\n",
    "label_cat1_vector = OneHotEncoder(inputCol='label_cat1_index',outputCol='label_cat1_vector')\n",
    "\n",
    "label_cat2_index = StringIndexer(inputCol='label2',outputCol='label_cat2_index')\n",
    "label_cat2_vector = OneHotEncoder(inputCol='label_cat2_index',outputCol='label_cat2_vector')\n",
    "\n",
    "label_cat3_index = StringIndexer(inputCol='label3a',outputCol='label_cat3_index')\n",
    "label_cat3_vector = OneHotEncoder(inputCol='label_cat3_index',outputCol='label_cat3_vector')\n",
    "\n",
    "label_cat4_index = StringIndexer(inputCol='label3b',outputCol='label_cat4_index')\n",
    "label_cat4_vector = OneHotEncoder(inputCol='label_cat4_index',outputCol='label_cat4_vector')\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "data_pipeline = Pipeline(stages=[label_cat0_vector,\n",
    "                                 label_cat1_index,label_cat1_vector,\n",
    "                                 label_cat2_index,label_cat2_vector,\n",
    "                                 label_cat3_index,label_cat3_vector,\n",
    "                                 label_cat4_index,label_cat4_vector])\n",
    "\n",
    "data_w_features = data_w_features.select(['Name','BA_pct','label_QD5','label1','label2','label3a','label3b','features'])\n",
    "data_prefinal = data_pipeline.fit(data_w_features).transform(data_w_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed03db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up data\n",
    "data_prefinal2 = data_prefinal.withColumnRenamed('BA_pct','label_q0')\n",
    "data_prefinal2 = data_prefinal2.withColumnRenamed('label_QD5','label_cat0')\n",
    "data_prefinal2 = data_prefinal2.withColumnRenamed('label_cat1_index','label_cat1')\n",
    "data_prefinal2 = data_prefinal2.withColumnRenamed('label_cat2_index','label_cat2')\n",
    "data_prefinal2 = data_prefinal2.withColumnRenamed('label_cat3_index','label_cat3')\n",
    "data_prefinal2 = data_prefinal2.withColumnRenamed('label_cat4_index','label_cat4')\n",
    "\n",
    "data_final = data_prefinal2.select(['Name',\n",
    "                                    'label_q0',\n",
    "                                    'label_cat0','label_cat1',\n",
    "                                    'label_cat2','label_cat3','label_cat4',\n",
    "                                    'features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42180862",
   "metadata": {},
   "source": [
    "* test a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe94a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_q0 = data_final.select(['label_q0','features'])\n",
    "train1_q0,test1_q0 = subset_q0.randomSplit([0.7,0.3])\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lm_A = LinearRegression(featuresCol='features',labelCol='label_q0',predictionCol='prediction')\n",
    "\n",
    "lmModel_1A = lm_A.fit(train1_q0)\n",
    "lmResults1A = lmModel_1A.evaluate(test1_q0)\n",
    "\n",
    "print(lmResults1A.rootMeanSquaredError, lmResults1A.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d0be50",
   "metadata": {},
   "source": [
    "<font color='purple'> ***Observations:*** </font> <br>\n",
    "...\n",
    "<br>\n",
    "<font color='orange'> ***Next step:*** </font> <br>\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f56c0",
   "metadata": {},
   "source": [
    "* test a logistic regression model using `label_cat0` (Spark's QuantileDiscretizer label column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4108cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg_test(dataset,modelname,labelName,featuresName,eval_comparison):\n",
    "    ''' # Select and split data \n",
    "    '''\n",
    "    subset = dataset.select([labelName,featuresName])\n",
    "    train,test = subset.randomSplit([0.7,0.3])\n",
    "\n",
    "    ''' # Instantiate and run model \n",
    "    '''\n",
    "    from pyspark.ml.classification import LogisticRegression\n",
    "    lr = LogisticRegression(featuresCol=featuresName,labelCol=labelName,predictionCol='prediction')\n",
    "\n",
    "    mymodel = lr.fit(train)\n",
    "    myresults = mymodel.transform(test)\n",
    "\n",
    "    ''' # Evaluate results on multiple metrics, output to df\n",
    "    '''\n",
    "    datasetName = myresults\n",
    "\n",
    "    from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "    multiEvaluator = MulticlassClassificationEvaluator(labelCol=labelName, predictionCol=\"prediction\")\n",
    "    binEvaluator = BinaryClassificationEvaluator(labelCol=labelName, rawPredictionCol=\"prediction\")\n",
    "\n",
    "    evalMetrics = {binEvaluator:['areaUnderROC','areaUnderPR'], \n",
    "                   multiEvaluator:['f1','weightedPrecision','weightedRecall','accuracy']}\n",
    "    evaluation = []\n",
    "    for each_evaluator in [binEvaluator,multiEvaluator]:\n",
    "        evaluator = each_evaluator\n",
    "        for each_metric in evalMetrics[evaluator]:        \n",
    "            metric = each_metric\n",
    "            result = evaluator.evaluate(datasetName, {evaluator.metricName: metric})\n",
    "            evaluation.append((metric,result))\n",
    "\n",
    "    column0 = [x for x,y in evaluation]\n",
    "    column1 = [y for x,y in evaluation]\n",
    "    eval_comparison['metric'] = column0\n",
    "    eval_comparison[modelname] = column1\n",
    "\n",
    "    return eval_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e73190",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_comparison = pd.DataFrame()\n",
    "dataset = data_final\n",
    "featuresName = 'features'\n",
    "labelName = 'label_cat0'\n",
    "modelname = 'lr_cat0'\n",
    "\n",
    "eval_comparison = log_reg_test(dataset,modelname,labelName,featuresName,eval_comparison)\n",
    "\n",
    "eval_comparison.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5c997e",
   "metadata": {},
   "source": [
    "<font color='purple'> ***Observations:*** </font> <br>\n",
    "...\n",
    "<br>\n",
    "<font color='orange'> ***Next step:*** </font> <br>\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd9f850",
   "metadata": {},
   "source": [
    "* test a logistic regression model using `label_cat1` (3-category BA labels: _low, medium, high_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1e7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_final\n",
    "featuresName = 'features'\n",
    "labelName = 'label_cat1'\n",
    "modelname = 'lr_cat1'\n",
    "\n",
    "eval_comparison = log_reg_test(dataset,modelname,labelName,featuresName,eval_comparison)\n",
    "\n",
    "eval_comparison.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b080d7cd",
   "metadata": {},
   "source": [
    "<font color='purple'> ***Observations:*** </font> <br>\n",
    "...\n",
    "<br>\n",
    "<font color='orange'> ***Next step:*** </font> <br>\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
